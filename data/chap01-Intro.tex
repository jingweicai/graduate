% !TeX root = ../thesis.tex

\chapter{Introduction}

\label{chap01:sec:introduction}

In recent years, computational demands, especially from Artificial Intelligence (AI) workloads, have been increasing rapidly. As shown in Figure~\ref{Deficit}~\cite{KartikHegde_AcceleratingDeepLearning_2022}, the amount of computation required for AI training increases by almost an order of magnitude per year. However, Moore's Law, which has driven the advances of hardware for several decades, is becoming harder to sustain. The traditional Very Large-Scale Integration (VLSI) system is implemented on a monolithic die, also known as system-on-chip (SoC). As manufacturing technology improvement (transistor density) has slowed down and the silicon area is approaching the limit of the lithographic reticle (\textit{e.g.} $26mm \times 33mm$ for ASML lithography~\cite{_MaskReticleWikiChip_, Huang_WaferLevelSystem_2021}), the performance (number of transistors) growth of traditional monolithic chip is going to stagnate~\cite{Loh_UnderstandingChipletsToday_2021, Naffziger_PioneeringChipletTechnology_2021}. As a result, there is an increasingly large gap between workloads and the hardware.
To fill the huge gap, People are motivated to explore more scalable computer architectures in this AI-boom and post-Moore era.

\nomenclature{SoC}{System-on-Chip,片上系统}
\nomenclature{VLSI}{Very Large-Scale Integration,超大规模集成电路}
\nomenclature{AI}{Artificial Intelligence,人工智能}
\nomenclature{D2D}{Die-to-Die,芯粒间}
\nomenclature{SoC}{System-on-Chip,片上系统}
\nomenclature{NRE}{Non-Recurring Engineering, 一次性工程}
\nomenclature{NoC}{Network-on-Chip (Network-on-Chiplet),片上网络}
\nomenclature{CoWoS}{Chip-on-Wafer-on-Substrate}
\nomenclature{InFO-SoW}{Integrated Fan-Out System-on-Wafer}
\nomenclature{LLM}{Large Language Model,大型语言模型}

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.99\linewidth]{../figures/INTRO/workload-hardware.pdf}
  \caption{Growing performance deficit. Y-Axis (Relative Increase) indicates how much the AI model training computation and hardware performance (in terms of FLOPS) have increased.\label{Deficit}}
\end{figure}

\section{Motivation}

Though manufacturing technology improvement has slowed down, integration technologies have made significant progress recently. Advanced packaging technologies such as Chip-on-Wafer-on-Substrate (CoWoS) and Integrated Fan-Out System-on-Wafer (InFO-SoW), allow many chiplets (silicon dies) to be integrated with ultra-high bandwidth and ultra-low latency, thus breaking through the “Area Wall” of traditional monolithic chips. Besides, partitioning a monolithic system into several chiplets can improve the overall yield of dies and allow reusability as well as heterogeneity, thereby reducing the cost. Chiplet architecture, which integrates and interconnects multiple modular-designed silicon dies into a large system, is considered the extension of Moore's Law by Moore himself~\cite{Moore_CrammingMoreComponents_1965} and the semiconductor industry. However, there are still many challenges to be addressed in the development of chiplet architecture, especially the chiplet-based interconnection network architecture:
\begin{itemize}
  \item  \textbf{The cost problem.} The cost advantage of chiplet architecture, which is widely recognized, is not easy to achieve due to the overhead of the packaging and die-to-die (D2D) interface. Compared with SoC, the cost of multi-chiplet systems is much more difficult to evaluate at the early design stage. Without careful evaluation, adopting chiplet architecture may lead to even higher costs. Previous works~\cite{Stow_CostAnalysisCostdriven_2016, Stow_CosteffectiveDesignScalable_2017} focus on the manufacturing cost of silicon but neglect other significant costs such as substrates, D2D overhead, and Non-Recurring Engineering (NRE) cost.
  \item \textbf{The challenge of scaling 2D-mesh.} 2D-mesh topology is widely used in on-chip networks because it is implementation-friendly. However, for large-scale multi-chiplet systems with thousands of cores, the performance of 2D-mesh networks is poor because the diameter is up to $O(\sqrt{N})$ and the bisection bandwidth is limited. There are significant differences in design approaches between large and small networks; thus, it is challenging to develop systems of various scales based on the typical 2D-mesh-NoC-based chiplets. At the same time, the routing algorithm is closely related to the topology and scale of the system. Connecting several NoCs together can lead to potential deadlocks and congestion problems\cite{Yin_ModularRoutingDesign_2018, Majumder_RemoteControlSimple_2021}.
  \item \textbf{The deficiencies of the unified interface.} Different scenarios and scales of systems have different requirements for chiplet interfaces. Parallel interfaces are low-latency and low-power, but the system can only use flat topologies such as the 2D-mesh~\cite{Pal_Designing2048Chiplet14336Core_2021, Nassif_SapphireRapidsNextGeneration_2022}. Building more efficient high-radix networks requires long-reach high-bandwidth serial interfaces, but the large latency and power consumption of serial interfaces are not suitable for small and energy-constrained systems. For frequent ``on-chip'' communications such as the handshake, synchronization, and coherence protocols, low-latency parallel interfaces are more suitable~\cite{Diemer_EfficientThroughputguaranteesLatencysensitive_2010, Li_ALPHALearningEnabledHighPerformance_2021, Yao_OpportunisticCompetitionOverhead_2016, Nassif_SapphireRapidsNextGeneration_2022}. However, for heavy network traffic such as the all-reduce operation of large amounts of data, high-throughput and long-reach serial interfaces are better choices~\cite{Nukada_PerformanceOptimizationAllreduce_2021, Kadiyala_COMETComprehensiveCluster_2022, Jouppi_TPUV4Optically_2023, Jouppi_TenLessonsThree_2021}. In modern high-performance systems, various network traffic patterns exist simultaneously~\cite{Avin_ComplexityTrafficTraces_2020, Bienia_BenchmarkingModernMultiprocessors_2011, Chandrasekaran_UnderstandingTrafficCharacteristics_2017}. In other words, there is no such one-size-fits-all universal interface for chiplet architecture.
  \item \textbf{The challenge of simulation.} Chiplet architecture integrates multiple silicon dies with ultra-high density and connectivity, breaking the boundary between on-chip and off-chip networks. Unified simulations on the entire network are necessary for evaluating chiplet interconnection architecture. Low-latency on-chip routers in multi-chiplet systems are directly connected by low-latency links of nanoseconds (ns), and circuit-level microarchitecture features, including buffer, link, switch, and flow-control, significantly impact the performance of chiplet-based systems. Therefore, it is necessary to use fine-grained cycle-accurate simulators to evaluate chiplet-based networks. However, existing cycle-accurate tools are inefficient for large-scale chiplet-based networks because they are designed for small-scale on-chip networks~\cite{Jiang_DetailedFlexibleCycleaccurate_2013,Agarwal_GARNETDetailedOnchip_2009,Ben-Itzhak_HNOCSModularOpensource_2012,Catania_NoximOpenExtensible_2015}, whose scale is no more than tens of routers.
  \item \textbf{The limitations of chiplet-based networks.} There are several major limitations and deficiencies of chiplet-based direct networks. Firstly, delivering through on-chiplet routers step-by-step is costly and unnecessary, especially for long-distance traffic that traverses numerous chiplets and hops. The alternative router-less solution, also known as isolated multi-ring (IMR)~\cite{Liu_IMRHighPerformanceLowCost_2016,Alazemi_RouterlessNetworkonChip_2018,Lin_DeepReinforcementLearning_2020}, is not suitable for large-scale multi-chiplet systems due to its limited routing flexibility and huge wiring requirement. Secondly, the cross-chip traffic drags down the local (intra-chiplet) network performance. In existing scale-out systems, long-distance packets need to traverse several chips before they reach the destination. When an originally well-designed NoC is used by heavy cross-chip traffic, the local NoC performance deteriorates due to the competition for network resources~\cite{Lotfi-Kamran_NOCOutMicroarchitectingScaleOut_2012,Nychis_OnchipNetworksNetworking_2012}. Thirdly, the routing design of inter-chip and intra-chip networks is also entangled. The on-chip network usually adopts a planar topology (\textit{e.g.} 2D-mesh), but the off-chip interconnection and topology can be high-radix and various. The off-chip interconnections mix up different dimensions and directions, thus leading to complex deadlock conditions. 
  \item \textbf{The challenge of further scaling-out.} Scaling large-scale chiplet-based chips out for large-scale supercomputers faces many challenges. Firstly, existing wafer-based systems, including \textit{Waferscale Processor}~\cite{Pal_Designing2048Chiplet14336Core_2021}, \textit{Wafer-Scale GPU}~\cite{Pal_ArchitectingWaferscaleProcessors_2019}, \textit{Wafer-Scale Engine (WSE)}~\cite{Cerebras_WaferScaleDeepLearning_2019, Lauterbach_PathSuccessfulWaferScale_2021, Lie_CerebrasArchitectureDeep_2022}, and \textit{DOJO}~\cite{Chang_DOJOSuperComputeSystem_2022, Talpes_DOJOMicroarchitectureTeslas_2022, GaneshVenkataramanan_ComputeEnablingAI_2022, Talpes_MicroarchitectureDOJOTeslas_2023}, are based on the 2D-mesh topology, which is not scalable due to the large diameter. Secondly, the off-wafer bandwidth has a significant gap with the on-wafer bandwidth, which places higher demands on the hierarchy and configurability. Thirdly, interconnecting 2D-mesh-on-wafer by high-radix topologies introduces serious routing problems. 
  \item \textbf{Lacking a good solution for AI.} There is no sufficiently scalable solution for AI supercomputer/datacenter. Fat-tree-based topologies are widely used in existing AI datacenters; however, they are extremely expensive to provide sufficient bandwidth~\cite{Hoefler_HammingMeshNetworkTopology_2022,Barroso_DatacenterComputerDesigning_2019,Gherghescu_IveGot99_2024,Gherghescu_LookTrainingLarge_2024}, especially at hyper-scale. The bandwidth and scalability are limited by the high-radix packet switch and the scale-up network, both of which are expensive to further scale. Multi-stage switching also introduces significant energy and latency overhead~\cite{Greenberg_CostCloudResearch_2008,Popoola_EnergyConsumptionSwitchcentric_2018,VictorAvelar_AIDisruptionChallenges_2023,Katebzadeh_EvaluationInfiniBandSwitch_2020}, potentially preventing system scaling. Direct networks, though they do not require high-radix switches, also face the scalability challenge. The Torus topology naturally fits the traffic of traditional AI workloads~\cite{Jouppi_TPUV4Optically_2023,Google_TPUV4Document_} with data/tensor/pipeline parallelism (DP/TP/PP)~\cite{Shoeybi_MegatronLMTrainingMultiBillion_2020,Narayanan_EfficientLargescaleLanguage_2021,Jiang_MegaScaleScalingLarge_2024,Huang_GpipeEfficientTraining_2019}. However, with the parameter/activation size scaling, more parallel strategies, including sequence parallelism (SP)~\cite{Korthikanti_ReducingActivationRecomputation_2022}, expert parallelism (EP) for mixture-of-experts (MOE) models~\cite{Rajbhandari_DeepSpeedMoE_2022,Lepikhin_GShardScalingGiant_2020,Fedus_SwitchTransformersScaling_2022,Riquelme_ScalingVisionSparse_2021,Jiang_MixtralExperts_2024,DeepSeek-AI_DeepSeekV2StrongEconomical_2024,DeepSeek-AI_DeepSeekV3TechnicalReport_2024,Dai_DeepSeekMoEUltimateExpert_2024,DeepSeek-AI_DeepSeekR1IncentivizingReasoning_2025} and context parallelism (CP) for long sequences~\cite{Jacobs_DeepSpeedUlyssesSystem_2023,Liu_RingAttentionBlockwise_2023,NVIDIA_ContextParallelismOverview_}, are adopted and combined, making deploying AI workloads on Torus complex. Moreover, the diameter of regular/twisted Torus networks is large, and the bisection bandwidth is insufficient for all-to-all traffic of MOE and ranking models~\cite{Camara_TwistedTorusTopologies_2010,Gangidi_RDMAEthernetDistributed_2024,Naumov_DeepLearningRecommendation_2019}. 
\end{itemize}

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.99\linewidth]{../figures/INTRO/Overview.pdf}
  \caption{Overview of the thesis. \label{overview}}
\end{figure}

\nomenclature{MLaaS}{Machine Learning as a Service, 机器学习作为服务}

\section{Outline and Contribution}
In Chapter 2, the background of chiplet architecture and interconnection networks is introduced. As shown in Figure~\ref{overview}, in Chapters 3$\sim$9, seven innovative studies that have driven the development of chiplet-based high-performance interconnection network architecture are presented. Chapter 10 introduces the conclusion of this thesis and provides three key insights. The major content and contributions of this thesis are summarized as follows:
\begin{itemize}
  \item \textbf{Chapter 3 Chiplet Actuary.} Cost-saving is a frequently mentioned advantage, but previous works rarely present quantitative demonstrations on the cost superiority of multi-chiplet integration over monolithic SoC. A quantitative cost model is built, and an analytical method is put forward for multi-chiplet systems based on three typical multi-chiplet integration technologies to analyze the cost benefits from yield improvement, chiplet and package reuse, and heterogeneity. The actual cost of multi-chiplet systems is re-examined from various perspectives, and the results show how to reduce the total cost of the VLSI system through appropriate multi-chiplet architecture.
  \item \textbf{Chapter 4 Scalable Methodology for Chiplet Networks.} Most on-chip networks are based on flat topologies such as 2D-mesh, which are inflexible and insufficient for large-scale multi-chiplet systems. To take full advantage of the multi-chiplet architecture and advanced packaging, an interconnection method that can flexibly establish high-radix interconnection networks from typical 2D-mesh-NoC-based chiplets is proposed. A minus-first-based deadlock-free adaptive routing algorithm is introduced for these multi-chiplet interconnection networks. Additionally, a general approach \textit{network interleaving} is used to balance the communication bandwidth within and between chiplets. Compared with traditional adaptive routing in 2D-mesh, the proposed methodology can significantly improve network performance in various cases. 
  \item \textbf{Chapter 5 Heterogeneous Chiplet Interfaces.} Most current multi-chiplet systems are based on one uniform die-to-die interface, which severely limits flexibility. The idea of \textit{Heterogeneous Interface (Hetero-IF)} allows chiplets to use two different interfaces (parallel IF and serial IF) at the same time. Hetero-IF can combine the advantages of different interfaces and cover up the disadvantages of each, thus improving flexibility and performance. Hetero-IF includes two typical implementations: \textit{Hetero-PHY} and \textit{Hetero-Channel}. Based on these two implementations, detailed usages and scheduling methods are discussed. The interconnection methods for hetero-IF-based multi-chiplet systems and deadlock-free routing algorithms are presented. Extensive evaluations, including simulation and circuit verification, are made on these systems. 
  \item \textbf{Chapter 6 Chiplet Network Simulator.} Chiplet-based networks are significantly different from traditional networks, thus presenting new challenges in evaluation. The design and implementation of the \textit{Chiplet Network Simulator (CNSim)} is presented, which is a cycle-accurate packet-parallel simulator supporting efficient simulation for large-scale chiplet-based (shared-memory) networks. In \textit{CNSim}, a packet-centric simulation architecture and an atomic-based hyper-threading mechanism are adopted, accelerating simulation speed by $11\times \sim 14\times$ compared with existing cycle-accurate simulators. Besides, the heterogeneous router/link microarchitecture and many other features, including hierarchical topologies, adaptive routing, and real workload traces integration, are implemented. The simulator and evaluation framework are open-sourced to the community
  \item \textbf{Chapter 7 Ring Road.} The traditional router-based NoC architecture has significant limitations for multi-chiplet systems. Therefore, people are motivated to design a new network architecture that can reduce router/wiring overhead, isolate on/off-chiplet traffic, and decouple inter/intra-chiplet routing design by combining the advantages of both routers and router-less rings. As a result, \textit{Ring Road} is proposed, in which high-speed isolated multi-rings are integrated with compact routers, thus achieving flexible traffic delivery with less router usage and overhead. A polar-coordinate-based description is presented to describe the topology, and corresponding deadlock-free routing algorithms are discussed. As a standalone NoC, \textit{Ring Road} is low-cost, low-latency, and high-performance. It can also be scaled out into multi-chiplet networks without redesigning the on-chip routing, regardless of inter-chip topology. With low-cost isolated ring channels, no matter how heavy the cross-chip traffic is, the local NoC performance remains consistent.
  \item \textbf{Chapter 8 Switch-Less Dragonfly on Wafers.} Existing high-performance computing (HPC) interconnection architectures are based on high-radix switches, which limit the injection/local performance and introduce latency/energy/cost overhead. A wafer-based interconnection architecture called \textit{Switch-Less-Dragonfly-on-Wafers} is proposed. By utilizing distributed high-bandwidth networks-on-chip-on-wafer, costly high-radix switches of the \textit{Dragonfly} topology are eliminated while increasing the injection/local throughput and maintaining the global throughput. Based on the proposed architecture, baseline and improved deadlock-free minimal/non-minimal routing algorithms with only one additional virtual channel are also introduced. Extensive evaluations show that the \textit{Switch-Less-Dragonfly-on-Wafers} outperforms the traditional switch-based \textit{Dragonfly} in both cost and performance. Similar approaches can be applied to other switch-based direct topologies, thus promising to power future large-scale supercomputers.
  \item \textbf{Chapter 9 RailX.} Traditional interconnection network architecture is neither scalable nor cost-effective enough for hyper-scale AI workloads. \textit{RailX} is proposed, which is a reconfigurable network architecture based on intra-node high-bandwidth integration and inter-node circuit switching. Nodes and optical switches are physically 2D-organized, achieving better scalability than existing centralized circuit switching networks. A novel interconnection method based on \textit{Hamiltonian Decomposition} theory is proposed to organize separate rail-based rings into \textit{all-to-all} topology, simultaneously optimizing ring-collective and all-to-all communication. More than $100$K chips with hyper bandwidth can be interconnected with a flat switching layer, and the diameter is only $2\sim4$ inter-node hops. The network cost per injection/All-Reduce bandwidth of \textit{RailX} is less than $10\%$ of the Fat-Tree, and the cost per bisection/All-to-All bandwidth is less than $50\%$ of the Fat-Tree. \textit{RailX} can also be used in the ML-as-a-service (MLaaS) scenario, where single or multiple training workloads with various shapes, scales, and parallelism strategies can be flexibly mapped, and failures can be worked around.

\end{itemize}
